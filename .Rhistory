x_train[279]
x_train[279,]
library(MASS)
data <- Boston
samplesSelect<-sample(c(1:length(data[,1])),length(data[,1])*0.7)
trainData<-data[samplesSelect,]
testData<-data[-samplesSelect,]
x_train<-trainData[-which(colnames(data)=="medv")]
y_train<-trainData[which(colnames(data)=="medv")]
x_test<-testData[-which(colnames(data)=="medv")]
y_test<-testData[which(colnames(data)=="medv")]
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- cbind(1,x)
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[j]])*activetionDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[t]]
initialweights[[t]]<- initialweights[[t]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
View(initialWeights)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- cbind(1,x)
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
compWeights <<- compWeights
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[j]])*activetionDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[t]]
initialweights[[t]]<- initialweights[[t]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
prediction <- function(x){
for (i in 1:length(fitWeights)) {
dotValues <- x%*%fitWeights[[i]]
x <- activation(dotValues)
}
return(x)
}
predictionMat <- function(x){
newX <- cbind(1,x)
predictValues <- apply(newX, 1,function(x)prediction(x))
print(predictValues)
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
View(compWeights)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- cbind(1,x)
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
compWeights <<- compWeights
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[j]])*activetionDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[t]]
initialweights[[t]]<- initialweights[[t]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
View(compWeights)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- as.matrix(cbind(1,x))
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[j]])*activetionDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[t]]
initialweights[[t]]<- initialweights[[t]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
View(y_train)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- as.matrix(cbind(1,x))
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples,] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[j]])*activetionDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[t]]
initialweights[[t]]<- initialweights[[t]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
View(activationDerivate)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- as.matrix(cbind(1,x))
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples,] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[j]])*activationDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[t]]
initialweights[[t]]<- initialweights[[t]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- as.matrix(cbind(1,x))
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples,] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient <<- gradient
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[j]])*activationDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[t]]
initialweights[[t]]<- initialweights[[t]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
View(gradient)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- as.matrix(cbind(1,x))
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples,] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[k]])*activationDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[t]]
initialweights[[t]]<- initialweights[[t]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- as.matrix(cbind(1,x))
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples,] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[k]])*activationDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[s]]
initialweights[[s]]<- initialweights[[s]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
predictionMat(x_test)
View(x_test)
View(fitWeights)
View(data)
library(MASS)
data <- Boston
samplesSelect<-sample(c(1:length(data[,1])),length(data[,1])*0.7)
trainData<-data[samplesSelect,]
testData<-data[-samplesSelect,]
x_train<-trainData[-which(colnames(data)=="medv")]
y_train<-trainData[which(colnames(data)=="medv")]
x_test<-testData[-which(colnames(data)=="medv")]
y_test<-testData[which(colnames(data)=="medv")]
x_train<-apply(x_train,2,function(x)scale(x,center=T,scale=T))
y_train<-scale(y_train,center=T,scale=T)
x_test<-apply(x_test,2,function(x)scale(x,center=T,scale=T))
y_test<-scale(y_test,center=T,scale=T)
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,2000)
predictionMat(x_test)
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,20000)
predictionMat(x_test)
y_train_inverse<-as.matrix(trainData[which(colnames(data)=="medv")])
y_test_inverse<-as.matrix(testData[which(colnames(data)=="medv")])
predict_inverse<-predict_values*sd(y_train_inverse)+mean(y_train_inverse)
myNeuralNet(c(13,3,3,2,1),'tanh')
training(x_train,y_train,0.001,20000)
predict_values<-predictionMat(x_test)
y_train_inverse<-as.matrix(trainData[which(colnames(data)=="medv")])
y_test_inverse<-as.matrix(testData[which(colnames(data)=="medv")])
predict_inverse<-predict_values*sd(y_train_inverse)+mean(y_train_inverse)
mse<-mean((y_test_inverse-predict_inverse)^2)
mae<-mean(abs(y_test_inverse-predict_inverse))
mse
mae
predict_inverse
install.packages('neuralnet')
View(x_train)
library(neuralnet)
network <- neuralnet(medv~,trainData,hidden=3)
library(neuralnet)
network <- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,trainData,hidden=3)
network
net.prediction<-compute(network,x_test)
View(net.prediction)
net.prediction[["net.result"]]
View(testData)
remove(list = ls())
sigmoidDerivate <- function(x){
sigmoidFun(x) *(1-sigmoidFun(x))
}
reluFun <- function(x){
max(0,x)
}
reluDerivate <- function(x){
as.numeric(x>0)
}
tanhDerivate <- function(x){
1 - tanh(x)^2
}
# Construct neural network
myNeuralNet <- function(layers,activationFun){
# choose activation function
if(activationFun == 'tanh'){
activation<<- tanh
activationDerivate <<- tanhDerivate
}else if(activationFun == 'sigmoid'){
activation <<- sigmoidFun
activationDerivate <<- sigmoidDerivate
}else if(activationFun == 'relu'){
activation <<- reluFun
activationDerivate <<- reluDerivate
}else {
return('activation is not support,please choose tanh,relu or sigmoid')
}
initialWeights <- list()
length(initialWeights) <- length(layers)-1
for (i in 1:(length(layers)-2)) {
rows <- layers[i]+1
cols <- layers[i+1]+1
initialWeights[[i]]<- matrix(nrow = rows,ncol = cols,rnorm(rows*cols))  # Initialize Weights
}
lastRow <- layers[length(initialWeights)]+1
lastCol <- layers[length(initialWeights)+1]
initialWeights[[length(initialWeights)]] <- matrix(nrow = lastRow,ncol = lastCol,rnorm(lastCol*lastRow))
initialWeights <<- initialWeights
}
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- as.matrix(cbind(1,x))
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- compWeights[[j]] %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples,] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[k]])*activationDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[s]]
initialweights[[s]]<- initialweights[[s]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
prediction <- function(x){
for (i in 1:length(fitWeights)) {
dotValues <- x%*%fitWeights[[i]]
x <- activation(dotValues)
}
return(x)
}
predictionMat <- function(x){
newX <- cbind(1,x)
predictValues <- apply(newX, 1,function(x)prediction(x))
print(predictValues)
}
library(MASS)
samplesSelect<-sample(c(1:length(Boston[,1])),length(Boston[,1])*0.7)
trainData<-Boston[samplesSelect,]
testData<-Boston[-samplesSelect,]
trainX<-trainData[-which(colnames(Boston)=="medv")]
trainY<-trainData[which(colnames(Boston)=="medv")]
testX<-testData[-which(colnames(Boston)=="medv")]
testY<-testData[which(colnames(Boston)=="medv")]
trainX<-apply(trainX,2,function(x)scale(x,center=T,scale=T))
trainX<-scale(trainY,center=T,scale=T)
testX<-apply(testX,2,function(x)scale(x,center=T,scale=T))
testY<-scale(testY,center=T,scale=T)
myNeuralNet(c(13,6,3,2,1),'tanh')
training(trainX,trainY,0.001,20000)
training <- function(x,y,learningRate,epochs=100){
initialweights <- initialWeights
x <- as.matrix(cbind(1,x))
for (i in 1:epochs) {
samples <- sample(1:length(x[,1]),1)
compWeights <- list(x[samples,])
length(compWeights) <-length(initialweights)
for (j in 1:length(initialweights)) {
values <- as.matrix(compWeights[[j]]) %*% initialweights[[j]]
compWeights[[j+1]]<-activation(values)
}
error <- y[samples,] - compWeights[[length(compWeights)]]
gradient <- list(error* activationDerivate(compWeights[[length(compWeights)]]))
for (k in (length(compWeights)-1):2) {
length(gradient) <- length(gradient) + 1
gradient[[length(gradient)]] <- gradient[[length(gradient)-1]]%*%t(initialweights[[k]])*activationDerivate(compWeights[[k]])
}
gradientReverse <- list()
length(gradientReverse) <- length(gradient)
for (m in 1:length(gradient)) {
gradientReverse[[m]] <- gradient[[(length(gradient))-m+1]]
}
for (s in 1:length(initialweights)) {
layerWeight <- as.numeric(compWeights[[s]])
gradient <- gradientReverse[[s]]
initialweights[[s]]<- initialweights[[s]] + learningRate*(layerWeight%*%gradient)
}
}
print(initialweights)
fitWeights <<- initialweights
}
myNeuralNet(c(13,6,3,2,1),'tanh')
training(trainX,trainY,0.001,20000)
devtools::document()
devtools::check()
devtools::build_vignettes()
devtools::build(vignettes=FALSE)
install.packages('../StatComp22092_1.0.tar.gz',repo=NULL)
